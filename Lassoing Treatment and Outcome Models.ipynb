{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for Surgery and Outcomes\n",
    "\n",
    "In this workbook, I apply the Lasso to developing parsimonious models for surgical outcomes and for application of treatment. The ideas follows the basic recipes in [Farrell (2015)](https://arxiv.org/abs/1309.4686). As I understand it, one implementation of the procedure is:\n",
    "\n",
    "1. Start with a perhaps large set of plausible variables, and fit a model of treatment/surgery selection with the Lasso to pare down the number of variables predicting treatment.\n",
    "2. Using a group lasso, estimate models of outcomes. Grouping the coefficients across the outcome models ensures that a uniform set of outcome predictors will be used. \n",
    "3. With these models, estimate treatment effects using a doubly-robust estimator, such as the augmented-inverse-probability-weighted estimator. This involves:\n",
    "    - Create propensity scores using the treatment model developed in step 1.\n",
    "    - Form weights using the propensity scores. Estimate outcome models and form treatment effects from outcome model predictions. \n",
    "    - Use weighted averages to compute the average treatment effect (ATE).\n",
    "\n",
    "First: set up the python `ipystata` package, and changing the directory to the right place. I begin by describing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipystata\n",
    "import os\n",
    "\n",
    "cd = os.getcwd()\n",
    "cdl = [cd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Matthew\\Documents\\github\\CivilWarSurgery\n",
      "\n",
      "Contains data from C:\\Users\\Matthew\\Documents\\github\\CivilWarSurgery\\DataFiles\\WorkingData.dta\n",
      "  obs:           498                          \n",
      " vars:            43                          6 Oct 2017 12:09\n",
      " size:       224,598                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              storage   display    value\n",
      "variable name   type    format     label      variable label\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "type            str20   %20s                  Type\n",
      "case            int     %10.0g                Case\n",
      "name            str11   %11s                  Name\n",
      "regno           str3    %9s                   RegNo\n",
      "regstate        str18   %18s                  RegState\n",
      "injury          str99   %99s                  Injury\n",
      "operation       str107  %107s                 Operation\n",
      "anesthetic      str12   %12s                  Anesthetic\n",
      "remarks         str79   %79s                  Remarks\n",
      "otherbattle     byte    %10.0g                OtherBattle\n",
      "misdum          float   %9.0g                 \n",
      "outcome         float   %9.0g                 \n",
      "operated        float   %9.0g                 Surgery\n",
      "expoper         float   %9.0g                 \n",
      "td1             byte    %8.0g                 type==arm\n",
      "td2             byte    %8.0g                 type==elbow\n",
      "td3             byte    %8.0g                 type==foot\n",
      "td4             byte    %8.0g                 type==forearm\n",
      "td5             byte    %8.0g                 type==hand\n",
      "td6             byte    %8.0g                 type==head\n",
      "td7             byte    %8.0g                 type==hip\n",
      "td8             byte    %8.0g                 type==knee\n",
      "td9             byte    %8.0g                 type==leg\n",
      "td10            byte    %8.0g                 type==neck, trunk shoulder\n",
      "td11            byte    %8.0g                 type==thigh\n",
      "sev             float   %9.0g                 severity\n",
      "sev2            float   %9.0g                 severity squared\n",
      "Ky22            float   %9.0g                 22nd Kentucky\n",
      "Oh16            float   %9.0g                 16th Ohio\n",
      "In54            float   %9.0g                 54th Indiana\n",
      "Oh42            float   %9.0g                 42nd Ohio\n",
      "Ia04            float   %9.0g                 4th Iowa\n",
      "Il13            float   %9.0g                 13th Illinois\n",
      "Mo29            float   %9.0g                 29th Missouri\n",
      "In49            float   %9.0g                 \n",
      "Mo06            float   %9.0g                 \n",
      "Oh114           float   %9.0g                 \n",
      "Mo31            float   %9.0g                 \n",
      "Oh58            float   %9.0g                 \n",
      "namelength      float   %9.0g                 \n",
      "longname        float   %9.0g                 >2 initials\n",
      "casualties      float   %9.0g                 \n",
      "lncas           float   %9.0g                 ln(reg. cases)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Sorted by: regstate  regno\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -i cdl\n",
    "chdir \"`cdl'\"\n",
    "\n",
    "clear all \n",
    "set more off \n",
    "\n",
    "use \"`cdl'\\DataFiles\\WorkingData.dta\"\n",
    "\n",
    "describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a set of commands that create globals to make passing variables easier, standardizes continuous variables, and then calculates the maximum value across all the variables for use in the lasso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(498 real changes made)\n",
      "(498 real changes made)\n",
      "(498 real changes made)\n",
      "(498 real changes made)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "global contvars sev sev2 longname lncas\n",
    "global contvarsex sev sev2 \n",
    "global dumvars td1 td2 td3 td4 td5 td6 td7 td8 td9 td10\n",
    "global dumregs Ky22 Oh16 In54 Oh42 Il13 Mo29 In49 Mo06 \n",
    "\n",
    "global yvar operated\n",
    "\n",
    "foreach v of global contvars {\n",
    "    quietly sum `v'\n",
    "    replace `v' = (`v' - r(mean))/r(sd)\n",
    "}\n",
    "\n",
    "global xlist $contvars $dumvars $dumregs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to standardize all the non-dummy variables, calculate the maximum value and also calculate $N$. This is useful for the recipe in [Farrell (2015)](https://arxiv.org/abs/1309.4686). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The program\n",
    "\n",
    "To do the analysis, I follow the previously-mocked-up Lasso program discussed [in this workbook](Developing%20Group%20Lasso%20Programs%20In%20Stata.ipynb). Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "note: argument todo unused\n",
      "note: argument gd unused\n",
      "note: argument H unused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "mata:\n",
    "    void gll_mata(M, todo, b, f, gd, H) {\n",
    "        \n",
    "        y  = moptimize_util_depvar(M, 1)\n",
    "        xb = moptimize_util_xb(M, b, 1)\n",
    "        \n",
    "        lam = moptimize_util_userinfo(M, 1)\n",
    "        g   = moptimize_util_userinfo(M, 2)\n",
    "        w   = moptimize_util_userinfo(M, 3)\n",
    "        w   = w/colsum(w)*rows(w)\n",
    "        \n",
    "        bt  = b[1::cols(b) - 1]\n",
    "        gb  = sqrt(rowsum(g)):*sqrt(rowsum((bt:^2):*g))\n",
    "        norm = colsum(gb)       \n",
    "       \n",
    "        lnf  = w:*((y :== 1) :*xb - ln(1 :+ exp(xb))) \n",
    "        \n",
    "        f = colsum(lnf) - norm*lam      \n",
    "    }\n",
    "end   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first Lasso, I first fit a completely unrestricted model - this is equivalent to using an identity grouping matrix, so we are not actually using a grouped lasso, but a special case of a group lasso, in which each variable is its own group. This makes computing the grouping matrix and lambda relatively easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda is\n",
      "  2.711880252\n",
      "\n",
      "Number variables\n",
      "  22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    \n",
    "    w = J(rows(y),1,1)\n",
    "    \n",
    "    lambda = 2*max(abs(X))/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1))^(1/2)\n",
    "    printf(\"Lambda is\")\n",
    "    lambda\n",
    "    g = I(cols(X))\n",
    "    printf(\"Number variables\")\n",
    "    cols(X)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Lasso on Treatment\n",
    "\n",
    "We now run the Lasso on the treatment variable. **Caution:** this can take awhile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                Number of obs     =        498\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |   .9031894   .1195488     7.55   0.000      .668878    1.137501\n",
      "        sev2 |   1.41e-07   .0009665     0.00   1.000    -.0018942    .0018945\n",
      "    longname |  -.0941415   .1145347    -0.82   0.411    -.3186254    .1303425\n",
      "       lncas |  -.3851187   .1132135    -3.40   0.001     -.607013   -.1632244\n",
      "         td1 |   .5871956   .4273241     1.37   0.169    -.2503442    1.424735\n",
      "         td2 |   1.45e-06   .0010378     0.00   0.999    -.0020326    .0020355\n",
      "         td3 |   2.22e-06   .0014392     0.00   0.999    -.0028186    .0028231\n",
      "         td4 |  -.0000232   .0047313    -0.00   0.996    -.0092964    .0092501\n",
      "         td5 |   1.187457   .3733153     3.18   0.001     .4557725    1.919142\n",
      "         td6 |  -.9205516   .5562424    -1.65   0.098    -2.010767    .1696634\n",
      "         td7 |  -6.48e-07   .0007695    -0.00   0.999    -.0015089    .0015076\n",
      "         td8 |   .4335916   .5632318     0.77   0.441    -.6703225    1.537506\n",
      "         td9 |  -.0302649   .3652469    -0.08   0.934    -.7461356    .6856058\n",
      "        td10 |  -.2326166   .3124632    -0.74   0.457    -.8450331       .3798\n",
      "        Ky22 |  -.0000132   .0037782    -0.00   0.997    -.0074182    .0073919\n",
      "        Oh16 |   .0000113   .0034159     0.00   0.997    -.0066838    .0067064\n",
      "        In54 |  -3.21e-06   .0016412    -0.00   0.998    -.0032199    .0032135\n",
      "        Oh42 |  -2.09e-07   .0010296    -0.00   1.000    -.0020182    .0020178\n",
      "        Il13 |  -9.63e-08   .0010475    -0.00   1.000    -.0020531     .002053\n",
      "        Mo29 |  -.0416533   .5760232    -0.07   0.942    -1.170638    1.087331\n",
      "        In49 |   7.31e-06   .0035193     0.00   0.998    -.0068904     .006905\n",
      "        Mo06 |   .1723401    .536511     0.32   0.748    -.8792023    1.223882\n",
      "       _cons |  -1.118555   .1939732    -5.77   0.000    -1.498736   -.7383746\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_conv_maxiter(M, 2000)\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso selects the following variables: `sev`, `longname`, `lncas`, `td1`, `td5`, `td6`, `td8`, `td9`, `td10`, `Mo29`,  and `Mo06`. So, severity of injury, having a longname/middle initial, a large amount of regimental casualties matter for treatment. `td1`, `td5`, `td6`, and `td8` are positive predictors of surgery - this makes sense, as these denote arm, hand, and knee injuries. `td9` and `td10` seem to be a strong negative predictors, but the interaction terms for these variables go in the opposite direction. Membership in regiments perhaps can be motivated by time and place on the battlefield. \n",
    "\n",
    "For the Lasso report, we note that the lasso reduced the model from 22 variables to 11.\n",
    "\n",
    "## The reduced model\n",
    "\n",
    "Here is the refit, parsimonious model selected by the Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   log pseudolikelihood = -303.87074  \n",
      "Iteration 1:   log pseudolikelihood = -230.93525  \n",
      "Iteration 2:   log pseudolikelihood = -227.52892  \n",
      "Iteration 3:   log pseudolikelihood = -227.47665  \n",
      "Iteration 4:   log pseudolikelihood = -227.47651  \n",
      "Iteration 5:   log pseudolikelihood = -227.47651  \n",
      "\n",
      "Logistic regression                             Number of obs     =        498\n",
      "                                                Wald chi2(10)     =      99.18\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log pseudolikelihood = -227.47651               Pseudo R2         =     0.2514\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "    operated |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |    .939183   .1275482     7.36   0.000     .6891931    1.189173\n",
      "    longname |  -.1623666   .1221384    -1.33   0.184    -.4017536    .0770203\n",
      "       lncas |  -.4810627   .1217991    -3.95   0.000    -.7197846   -.2423409\n",
      "         td1 |   1.133494   .4478126     2.53   0.011      .255797     2.01119\n",
      "         td5 |    1.62148   .3972601     4.08   0.000     .8428645    2.400096\n",
      "         td6 |  -1.918549   .7155976    -2.68   0.007    -3.321094   -.5160034\n",
      "         td8 |   1.276275   .5655571     2.26   0.024     .1678033    2.384746\n",
      "        td10 |  -.3559884   .3217611    -1.11   0.269    -.9866285    .2746517\n",
      "        Mo29 |  -1.143297   .6108493    -1.87   0.061     -2.34054    .0539453\n",
      "        Mo06 |   1.020732   .4873903     2.09   0.036     .0654643    1.975999\n",
      "       _cons |    -1.2464   .1647221    -7.57   0.000     -1.56925   -.9235511\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "logit operated sev longname lncas td1 td5 td6 td8 td10 Mo29  Mo06, robust\n",
    "predict ps, p\n",
    "gen w = 1/ps*operated + 1/(1-ps)*(1-operated)\n",
    "drop ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Group) Lassoing of Outcomes\n",
    "\n",
    "I now fit the grouped lasso to get some parsimonious models of outcomes. The chief idea is to generate interaction terms for outcomes, and then group each coefficient with its interaction term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome control variables:\n",
    "\n",
    "To select control variables for the outcome equation, I do the following. I first interact each variable with the operated dummy, so that we now have, effectively, two separate sets of coefficients: those that predict the outcome for the \"operated\" sample, and those that predict the outcome for the \"not operated\" sample. \n",
    "\n",
    "The coefficients and interacted coefficients are then grouped, so only those variables that help in predicting outcomes among both operated and not operated groups get included as additional controls.\n",
    "\n",
    "Note that since the variables are again dummies, and the rest of the candidate explanatory variables have already been normalized, we do not need to go through that step again. \n",
    "\n",
    "### Generating interactions\n",
    "\n",
    "Here, we remake our list of variables, omitting our instruments `longname` and `lncas`. But note that it actually doesn't matter if one leaves them in as they get dropped by the lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "global xlist $contvarsex $dumvars $dumregs \n",
    "\n",
    "global xoutlist\n",
    "foreach variable in $xlist {\n",
    "    gen io_`variable' = `variable'*operated\n",
    "    global xoutlist $xoutlist `variable' io_`variable'\n",
    "}\n",
    "\n",
    "global yvar outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trick for making the grouping matrix is then to just double up an identity matrix. This means that the coefficient on a variable and its interaction term is grouped together. So, if one is included, both are - meaning that the variable has to have explanatory power in predicting the outcome for both the treated/surgical and non-treated/nonsurgical group. \n",
    "\n",
    "**Notes**: the following two blocks of code can take awhile to run. The optimization routine runs in two stages. In the first stage, it uses Nelder-Mead which is fast but crude. Once it gets close to the optimum, it switches to the conventional maximization routine, which is more able to set coefficients close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stata -s gl \n",
    "mata:\n",
    "    st_view(X=.,.,\"$xoutlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    st_view(w=.,.,\"w\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1))^(1/2)\n",
    "\n",
    "    g = I(cols(X)/2)#J(1,2,1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                Number of obs     =        498\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |   -.568967   .1400847    -4.06   0.000     -.843528   -.2944061\n",
      "      io_sev |   .1883502   .2014239     0.94   0.350    -.2064334    .5831337\n",
      "        sev2 |   5.80e-07   .0010137     0.00   1.000    -.0019862    .0019873\n",
      "     io_sev2 |   1.48e-06   .0009563     0.00   0.999    -.0018729    .0018758\n",
      "         td1 |   .4454108   .4347585     1.02   0.306    -.4067003    1.297522\n",
      "      io_td1 |   .0947225   .3148721     0.30   0.764    -.5224155    .7118605\n",
      "         td2 |   8.17e-07   .0008692     0.00   0.999    -.0017027    .0017043\n",
      "      io_td2 |   8.46e-07    .000872     0.00   0.999    -.0017083      .00171\n",
      "         td3 |  -3.34e-07   .0008634    -0.00   1.000    -.0016925    .0016918\n",
      "      io_td3 |  -9.14e-07   .0008437    -0.00   0.999    -.0016546    .0016528\n",
      "         td4 |   3.95e-06   .0016659     0.00   0.998    -.0032612    .0032691\n",
      "      io_td4 |   2.64e-06   .0013854     0.00   0.998    -.0027127    .0027179\n",
      "         td5 |   .2713236   .4373572     0.62   0.535    -.5858807    1.128528\n",
      "      io_td5 |   .0188904   .2501457     0.08   0.940    -.4713862     .509167\n",
      "         td6 |  -8.70e-06   .0022175    -0.00   0.997     -.004355    .0043376\n",
      "      io_td6 |   1.22e-06   .0016275     0.00   0.999    -.0031887    .0031911\n",
      "         td7 |  -9.32e-07   .0009864    -0.00   0.999    -.0019342    .0019323\n",
      "      io_td7 |   1.77e-06   .0009906     0.00   0.999    -.0019398    .0019433\n",
      "         td8 |  -.5551649   .4643335    -1.20   0.232    -1.465242    .3549122\n",
      "      io_td8 |  -.2322143   .3705548    -0.63   0.531    -.9584883    .4940597\n",
      "         td9 |   1.91e-06   .0010708     0.00   0.999    -.0020969    .0021007\n",
      "      io_td9 |   1.07e-06   .0009415     0.00   0.999    -.0018443    .0018465\n",
      "        td10 |  -.8189122   .3439646    -2.38   0.017     -1.49307   -.1447538\n",
      "     io_td10 |   .8593412   .4732827     1.82   0.069    -.0682758    1.786958\n",
      "        Ky22 |  -1.37e-06   .0009602    -0.00   0.999    -.0018833    .0018806\n",
      "     io_Ky22 |   2.05e-07    .000891     0.00   1.000    -.0017462    .0017466\n",
      "        Oh16 |   .3329635   .3199988     1.04   0.298    -.2942227    .9601496\n",
      "     io_Oh16 |   .5372647   .4742877     1.13   0.257    -.3923221    1.466851\n",
      "        In54 |  -.0000131   .0026234    -0.01   0.996    -.0051549    .0051286\n",
      "     io_In54 |   6.50e-07   .0019255     0.00   1.000    -.0037733    .0037746\n",
      "        Oh42 |  -.0000121   .0036304    -0.00   0.997    -.0071276    .0071033\n",
      "     io_Oh42 |   2.51e-06    .002063     0.00   0.999    -.0040409    .0040459\n",
      "        Il13 |   .2810732   .4143487     0.68   0.498    -.5310353    1.093182\n",
      "     io_Il13 |   .1330676   .3016969     0.44   0.659    -.4582475    .7243827\n",
      "        Mo29 |   1.87e-06   .0010556     0.00   0.999    -.0020671    .0020708\n",
      "     io_Mo29 |   6.83e-07   .0010422     0.00   0.999    -.0020419    .0020433\n",
      "        In49 |  -6.56e-06   .0020184    -0.00   0.997    -.0039625    .0039494\n",
      "     io_In49 |   4.38e-07    .001451     0.00   1.000    -.0028434    .0028443\n",
      "        Mo06 |  -1.30e-07   .0009792    -0.00   1.000    -.0019193     .001919\n",
      "     io_Mo06 |  -4.98e-07   .0007016    -0.00   0.999    -.0013757    .0013747\n",
      "       _cons |   1.562686   .1786329     8.75   0.000     1.212572    1.912801\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 50000)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_technique(M, \"nm\")\n",
    "    moptimize_init_nmsimplexdeltas(M,J(1,cols(X),.05))\n",
    "    moptimize(M)\n",
    "    b = moptimize_result_coefs(M)\n",
    "end  \n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 1000)\n",
    "    moptimize_init_trace_value(M, \"off\") \n",
    "    moptimize_init_eq_coefs(M, 1, b)    \n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glancing at the above coefficients, we see that the real contributors are: `sev`, `td1`, `td5`, `td8`, and `td10`, `Oh16`, and `Il13`. One could quibble about a few other variables, but these very seldomly make an impact on what follows.  \n",
    "\n",
    "For the lasso, we start with 20 variables grouped in sets of 2. The right way of saying things is that our initial set of 20 groups of variables is reduced to 5 groups of variables.  \n",
    "\n",
    "**Note**: while the routine above says that it has not converged, this s really just because the coefficients that are effectively zero are being pushed further and further towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating treatment effects\n",
    "\n",
    "Now that I have trimmed the model down to its components, I follow  [Farrell (2015)](https://arxiv.org/abs/1309.4686) and use the parisominious model to estimate treatment effects. Here, I just preview results using `Stata`'s canned `teffects` package. But in the workbook where I actually put together the treatment effects and graphs, I do it by hand following [Wooldridge, Chapter 21, pp. 930-931](https://mitpress.mit.edu/books/econometric-analysis-cross-section-and-panel-data).\n",
    "\n",
    "Reason being, I'm not sure exactly what Stata's package is doing, and there doesn't appear to be any documentation describing how it works in detail. But as a preview, it works fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   EE criterion =  1.403e-15  \n",
      "Iteration 1:   EE criterion =  2.267e-27  \n",
      "\n",
      "Treatment-effects estimation                    Number of obs     =        498\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : logit by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "ATE          |\n",
      "    operated |\n",
      "   (1 vs 0)  |    .113198    .039278     2.88   0.004     .0362145    .1901815\n",
      "-------------+----------------------------------------------------------------\n",
      "POmean       |\n",
      "    operated |\n",
      "          0  |   .7657844   .0271102    28.25   0.000     .7126494    .8189194\n",
      "-------------+----------------------------------------------------------------\n",
      "OME0         |\n",
      "         sev |  -.9910786   .1697128    -5.84   0.000     -1.32371   -.6584476\n",
      "         td1 |   1.196484    1.03896     1.15   0.249    -.8398411    3.232809\n",
      "         td5 |   1.750337   1.145717     1.53   0.127    -.4952279    3.995902\n",
      "         td8 |  -.9650301   .7739315    -1.25   0.212    -2.481908    .5518477\n",
      "        td10 |  -.9387819   .2967388    -3.16   0.002    -1.520379   -.3571845\n",
      "        Il13 |   1.592631   .7904994     2.01   0.044     .0432806    3.141982\n",
      "       _cons |   1.206684   .1867637     6.46   0.000     .8406337    1.572734\n",
      "-------------+----------------------------------------------------------------\n",
      "OME1         |\n",
      "         sev |  -.3434469    .245095    -1.40   0.161    -.8238242    .1369305\n",
      "         td1 |    .675185   .7140829     0.95   0.344    -.7243917    2.074762\n",
      "         td5 |   .2589891   .7208325     0.36   0.719    -1.153817    1.671795\n",
      "         td8 |  -1.033223   .7724797    -1.34   0.181    -2.547255    .4808096\n",
      "        td10 |   .4728156   .7938481     0.60   0.551    -1.083098    2.028729\n",
      "        Il13 |   .1132932   1.169893     0.10   0.923    -2.179655    2.406242\n",
      "       _cons |   1.711188   .3434813     4.98   0.000     1.037977    2.384399\n",
      "-------------+----------------------------------------------------------------\n",
      "TME1         |\n",
      "         sev |    .939183   .1274201     7.37   0.000     .6894443    1.188922\n",
      "    longname |  -.1623666   .1220157    -1.33   0.183    -.4015131    .0767798\n",
      "       lncas |  -.4810627   .1216768    -3.95   0.000    -.7195448   -.2425807\n",
      "         td1 |   1.133494   .4473628     2.53   0.011     .2566787    2.010308\n",
      "         td5 |    1.62148   .3968611     4.09   0.000     .8436466    2.399313\n",
      "         td6 |  -1.918549   .7148787    -2.68   0.007    -3.319685   -.5174123\n",
      "         td8 |   1.276275    .564989     2.26   0.024     .1689168    2.383633\n",
      "        td10 |  -.3559884   .3214379    -1.11   0.268     -.985995    .2740182\n",
      "        Mo29 |  -1.143297   .6102357    -1.87   0.061    -2.339337    .0527426\n",
      "        Mo06 |   1.020732   .4869007     2.10   0.036     .0664238    1.975039\n",
      "       _cons |    -1.2464   .1645566    -7.57   0.000    -1.568926   -.9238754\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 0:   log pseudolikelihood = -168.47643  \n",
      "Iteration 1:   log pseudolikelihood = -159.20698  \n",
      "Iteration 2:   log pseudolikelihood = -155.18428  \n",
      "Iteration 3:   log pseudolikelihood = -153.46737  \n",
      "Iteration 4:   log pseudolikelihood = -153.44872  \n",
      "Iteration 5:   log pseudolikelihood = -153.44872  \n",
      "\n",
      "Logistic regression                             Number of obs     =        149\n",
      "                                                Wald chi2(6)      =      11.35\n",
      "                                                Prob > chi2       =     0.0782\n",
      "Log pseudolikelihood = -153.44872               Pseudo R2         =     0.0892\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |  -.4681662   .2692816    -1.74   0.082    -.9959485     .059616\n",
      "         td1 |   .4481514     .72994     0.61   0.539    -.9825047    1.878807\n",
      "         td5 |   .0144003   .7969082     0.02   0.986    -1.547511    1.576312\n",
      "         td8 |  -2.044119   .8833833    -2.31   0.021    -3.775519   -.3127199\n",
      "        td10 |  -.0779277   .8592648    -0.09   0.928    -1.762056      1.6062\n",
      "        Il13 |   .9567052   1.244172     0.77   0.442    -1.481827    3.395238\n",
      "       _cons |   2.171866   .4453934     4.88   0.000     1.298911    3.044821\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "teffects aipw (outcome sev td1 td5 td8 td10 Il13, logit) ///\n",
    "      (operated sev longname lncas td1 td5 td6 td8 td10 Mo29 Mo06, logit), aequations\n",
    "\n",
    "    logit outcome sev td1 td5 td8 td10 Il13 [pweight=w] if operated == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An extension - three treatments:\n",
    "\n",
    "## Resection/Excision, Amputation, and Conservation\n",
    "\n",
    "Here, following up a referee's suggestion, I look at amputation, versus excision/resection, versus no treatment, which is the typical breakdown followed in the Compendium of the War of the Rebellion. The logic here is that there is a difference between amputation and excision, as the latter involves digging around in a wound. Is there a difference in recovery rates when looking at these things? \n",
    "\n",
    "While this seems like an obvious thing to do, it wasn't obvious how to estimate outcome models that made sense. Of course, the lasso provides a means of picking out a parsimonious outcome model when there are multiple treatments. \n",
    "\n",
    "The very first thing that is needed is a lasso function that can handle multiple alternatives. Here is the `Mata` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "note: argument todo unused\n",
      "note: argument gr unused\n",
      "note: argument H unused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "mata:\n",
    "    void gltril_mata(M, todo, b, f, gr, H) {\n",
    "        \n",
    "        y  = moptimize_util_depvar(M, 1)\n",
    "        xb1 = moptimize_util_xb(M, b, 1)\n",
    "        xb2 = moptimize_util_xb(M, b, 2)\n",
    "\n",
    "        lam = moptimize_util_userinfo(M, 1)\n",
    "        g   = moptimize_util_userinfo(M, 2)\n",
    "        w   = moptimize_util_userinfo(M, 3)\n",
    "        w   = w/colsum(w)*rows(w)\n",
    "        \n",
    "        b1  = b[1::cols(b)/2]\n",
    "        b2  = b[cols(b)/2 + 1::cols(b)]\n",
    "\n",
    "        b1 = b1[1::cols(b1)-1]\n",
    "        b2 = b2[1::cols(b2)-1]\n",
    "\n",
    "        bt = b1, b2\n",
    "\n",
    "        gb  = sqrt(rowsum(g)):*sqrt(rowsum((bt:^2):*g))\n",
    "        norm = colsum(gb)       \n",
    "    \n",
    "        lnf  = (y :== 1) :*xb1 + (y :==2 ) :*xb2 - ln(1 :+ exp(xb1) :+ exp(xb2))       \n",
    "        \n",
    "        f = sum(lnf) - norm*lam\n",
    "    }\n",
    "end   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now reset the outcomes. We now reset globals to hold all the variables again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "global xlist $contvars $dumvars $dumregs\n",
    "global yvar expoper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I pull the variables into `Mata` and recalculate $\\lambda$. Note that because there are multiple treatments, the calculation is a little different than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda is\n",
      "  3.23185689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    w = J(rows(y),1,1)\n",
    "    \n",
    "    lambda = 2*max(abs(X))*sqrt(2)/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1)/sqrt(2))^(1/2)   \n",
    "    printf(\"Lambda is\")\n",
    "    lambda\n",
    "    g = J(1,2,1)#I(cols(X))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "As before, we first run things with Nelder-Mead, and then let it run with usual optimization routines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                Number of obs     =        498\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "eq1          |\n",
      "         sev |   1.184415   .1526159     7.76   0.000      .885293    1.483536\n",
      "        sev2 |   6.97e-07   .0007355     0.00   0.999    -.0014409    .0014423\n",
      "    longname |  -.0999266   .1401354    -0.71   0.476    -.3745869    .1747336\n",
      "       lncas |  -.0094561   .1352477    -0.07   0.944    -.2745367    .2556245\n",
      "         td1 |    .081713    .277214     0.29   0.768    -.4616164    .6250423\n",
      "         td2 |  -4.00e-06   .0017101    -0.00   0.998    -.0033557    .0033477\n",
      "         td3 |   3.43e-06   .0012884     0.00   0.998    -.0025217    .0025286\n",
      "         td4 |  -9.53e-07   .0011246    -0.00   0.999    -.0022052    .0022033\n",
      "         td5 |   1.690124   .3967587     4.26   0.000     .9124916    2.467757\n",
      "         td6 |  -.2947001   .5707919    -0.52   0.606    -1.413432    .8240315\n",
      "         td7 |  -5.38e-06   .0015868    -0.00   0.997    -.0031154    .0031047\n",
      "         td8 |   .4183665   .6000124     0.70   0.486    -.7576362    1.594369\n",
      "         td9 |   .0917347   .2370038     0.39   0.699    -.3727843    .5562536\n",
      "        td10 |   -1.14564   .5160743    -2.22   0.026    -2.157127   -.1341527\n",
      "        Ky22 |  -2.30e-07   .0007737    -0.00   1.000    -.0015166    .0015161\n",
      "        Oh16 |   6.63e-07   .0008887     0.00   0.999    -.0017411    .0017425\n",
      "        In54 |   9.00e-07   .0014769     0.00   1.000    -.0028938    .0028956\n",
      "        Oh42 |  -1.10e-07   .0004295    -0.00   1.000    -.0008419    .0008417\n",
      "        Il13 |   1.52e-07   .0004283     0.00   1.000    -.0008392    .0008395\n",
      "        Mo29 |  -7.95e-07   .0013322    -0.00   1.000    -.0026118    .0026102\n",
      "        In49 |  -4.60e-08   .0011643    -0.00   1.000     -.002282    .0022819\n",
      "        Mo06 |   1.03e-06   .0008816     0.00   0.999     -.001727     .001729\n",
      "       _cons |   -1.88418   .2169482    -8.68   0.000    -2.309391   -1.458969\n",
      "-------------+----------------------------------------------------------------\n",
      "eq2          |\n",
      "         sev |   .5285208   .1478087     3.58   0.000     .2388211    .8182205\n",
      "        sev2 |   3.20e-07    .000588     0.00   1.000    -.0011521    .0011528\n",
      "    longname |  -.0023278   .1034672    -0.02   0.982    -.2051197    .2004641\n",
      "       lncas |  -.6593249   .1315572    -5.01   0.000    -.9171723   -.4014775\n",
      "         td1 |   .2475541   .5296808     0.47   0.640    -.7906013    1.285709\n",
      "         td2 |   9.44e-06    .002288     0.00   0.997     -.004475    .0044938\n",
      "         td3 |  -2.94e-06   .0012806    -0.00   0.998    -.0025128    .0025069\n",
      "         td4 |  -1.40e-06   .0010759    -0.00   0.999    -.0021102    .0021074\n",
      "         td5 |  -.3045302   .4525286    -0.67   0.501     -1.19147    .5824095\n",
      "         td6 |  -.1133863   .3239703    -0.35   0.726    -.7483564    .5215838\n",
      "         td7 |   2.93e-06   .0013427     0.00   0.998    -.0026287    .0026346\n",
      "         td8 |  -.1102574   .3137451    -0.35   0.725    -.7251864    .5046717\n",
      "         td9 |  -.2538901   .4239165    -0.60   0.549    -1.084751     .576971\n",
      "        td10 |   .2744943   .2809035     0.98   0.328    -.2760665    .8250551\n",
      "        Ky22 |  -6.50e-07   .0006117    -0.00   0.999    -.0011995    .0011982\n",
      "        Oh16 |   1.08e-06    .001063     0.00   0.999    -.0020823    .0020845\n",
      "        In54 |  -9.47e-06   .0021057    -0.00   0.996    -.0041366    .0041177\n",
      "        Oh42 |  -2.73e-07   .0007675    -0.00   1.000    -.0015046    .0015041\n",
      "        Il13 |  -1.34e-07   .0007665    -0.00   1.000    -.0015024    .0015021\n",
      "        Mo29 |  -6.00e-06   .0016374    -0.00   0.997    -.0032153    .0032032\n",
      "        In49 |   3.59e-06   .0012654     0.00   0.998    -.0024766    .0024838\n",
      "        Mo06 |   1.32e-06    .000809     0.00   0.999    -.0015843     .001587\n",
      "       _cons |  -1.836869    .199847    -9.19   0.000    -2.228562   -1.445176\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gltril_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_eq_indepvars(M, 2, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 10000)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_technique(M, \"nm\")\n",
    "    moptimize_init_nmsimplexdeltas(M,J(1,cols(X),.1))\n",
    "    moptimize(M)\n",
    "\n",
    "    b = moptimize_result_coefs(M)\n",
    "end  \n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gltril_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_eq_indepvars(M, 2, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 500)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_eq_coefs(M,1,b[1::cols(b)/2])\n",
    "    moptimize_init_eq_coefs(M,2,b[cols(b)/2+1::cols(b)])\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the selected predictors are `sev`, `longname`, `lncas`, `td1`, `td5`, `td6`, `td8`, `td9`, and `td10`. \n",
    "\n",
    "** Note: ** In the process of fitting the model, the analysis revealed that the dummy `td6` more or less perfectly predicted membership in one or more treatment classes. This is the dummy for \"head wounds,\" which evidently were almost never treated. Hence, we dropped all of these from the subsequent analysis. In any event, here is our pared-down treatment model, as suggested by the lasso: \n",
    "\n",
    "The set of variables are thus reduced from 22 to 9 for the multiple outcomes model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   log pseudolikelihood = -406.58183  \n",
      "Iteration 1:   log pseudolikelihood = -303.65873  \n",
      "Iteration 2:   log pseudolikelihood = -287.37341  \n",
      "Iteration 3:   log pseudolikelihood = -284.77562  \n",
      "Iteration 4:   log pseudolikelihood =  -284.3115  \n",
      "Iteration 5:   log pseudolikelihood = -284.20538  \n",
      "Iteration 6:   log pseudolikelihood = -284.18204  \n",
      "Iteration 7:   log pseudolikelihood = -284.17621  \n",
      "Iteration 8:   log pseudolikelihood = -284.17508  \n",
      "Iteration 9:   log pseudolikelihood = -284.17487  \n",
      "Iteration 10:  log pseudolikelihood = -284.17485  \n",
      "\n",
      "Multinomial logistic regression                 Number of obs     =        498\n",
      "                                                Wald chi2(18)     =    6478.25\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log pseudolikelihood = -284.17485               Pseudo R2         =     0.3011\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "     expoper |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "0            |  (base outcome)\n",
      "-------------+----------------------------------------------------------------\n",
      "1            |\n",
      "         sev |   1.393397   .1614445     8.63   0.000     1.076971    1.709822\n",
      "    longname |  -.3218576   .1640857    -1.96   0.050    -.6434596   -.0002556\n",
      "       lncas |  -.0055322   .1729908    -0.03   0.974     -.344588    .3335236\n",
      "         td1 |   .7681894   .5216171     1.47   0.141    -.2541613     1.79054\n",
      "         td5 |   2.440994   .4693117     5.20   0.000      1.52116    3.360828\n",
      "         td6 |   -15.8972   .3734779   -42.57   0.000     -16.6292    -15.1652\n",
      "         td8 |   2.108388   .7009465     3.01   0.003     .7345583    3.482218\n",
      "         td9 |   .2692153   .4451575     0.60   0.545    -.6032774    1.141708\n",
      "        td10 |   -15.4087   .3171636   -48.58   0.000    -16.03032   -14.78707\n",
      "       _cons |   -2.16267   .2614177    -8.27   0.000    -2.675039   -1.650301\n",
      "-------------+----------------------------------------------------------------\n",
      "2            |\n",
      "         sev |   .5273736   .1671362     3.16   0.002     .1997927    .8549544\n",
      "    longname |   -.053014   .1471949    -0.36   0.719    -.3415107    .2354827\n",
      "       lncas |  -.7588499   .1362054    -5.57   0.000    -1.025808   -.4918923\n",
      "         td1 |   1.234787   .5225942     2.36   0.018     .2105215    2.259053\n",
      "         td5 |  -.5661769   .8210192    -0.69   0.490    -2.175345    1.042991\n",
      "         td6 |  -1.123949     .73686    -1.53   0.127    -2.568168    .3202705\n",
      "         td8 |  -.5178484   1.126783    -0.46   0.646    -2.726302    1.690606\n",
      "         td9 |   -1.59518    .732723    -2.18   0.029    -3.031291   -.1590694\n",
      "        td10 |   .1761346   .3539767     0.50   0.619    -.5176471    .8699163\n",
      "       _cons |  -1.790745   .2401828    -7.46   0.000    -2.261494   -1.319995\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "mlogit expoper sev longname lncas td1 td5 td6 td8 td9 td10, vce(robust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a conceptual problem with the above, in that those \"very large\" negative coefficients effectively mean that wounded soldiers with head wounds and neck, trunk, shoulder wounds never wind up with amputations. So, we will proceed after dropping these variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already preserved\n",
      "r(621);\n",
      "\n",
      "(0 observations deleted)\n",
      "\n",
      "Lambda is\n",
      "  3.633265754\n",
      "\n",
      "                 <istmt>:  3499  M not found\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "r(3499);\n",
      "\n",
      "command moptimize_init_evaluatortype is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_eq_indepvars is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_eq_indepvars is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_depvar is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_userinfo is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_userinfo is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_userinfo is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_singularHmethod is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_conv_maxiter is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_trace_value is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_technique is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize_init_nmsimplexdeltas is unrecognized\n",
      "r(199);\n",
      "\n",
      "command moptimize is unrecognized\n",
      "r(199);\n",
      "\n",
      "command b is unrecognized\n",
      "r(199);\n",
      "\n",
      "command end is unrecognized\n",
      "r(199);\n",
      "\n",
      "convergence not achieved\n",
      "\n",
      "                                                Number of obs     =        335\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "eq1          |\n",
      "         sev |   1.076359   .1458249     7.38   0.000     .7905473    1.362171\n",
      "        sev2 |  -4.90e-07    .000578    -0.00   0.999    -.0011333    .0011324\n",
      "    longname |  -.1249723   .1416954    -0.88   0.378    -.4026901    .1527455\n",
      "       lncas |  -.0103171   .1371203    -0.08   0.940    -.2790681    .2584338\n",
      "         td1 |  -.0004104   .0488805    -0.01   0.993    -.0962145    .0953937\n",
      "         td2 |   .0002315    .620181     0.00   1.000    -1.215301    1.215764\n",
      "         td3 |  -1.44e-06   .0008935    -0.00   0.999    -.0017528    .0017499\n",
      "         td4 |  -.0039793   .5157712    -0.01   0.994    -1.014872    1.006914\n",
      "         td5 |    .871622   .3729243     2.34   0.019     .1407038     1.60254\n",
      "         td8 |   .0228743   .5740263     0.04   0.968    -1.102197    1.147945\n",
      "         td9 |  -.0098192   .1750814    -0.06   0.955    -.3529725     .333334\n",
      "        Ky22 |  -1.10e-06   .0008284    -0.00   0.999    -.0016247    .0016225\n",
      "        Oh16 |   4.79e-06   .0014797     0.00   0.997    -.0028955     .002905\n",
      "        In54 |  -1.03e-06   .0007564    -0.00   0.999    -.0014836    .0014816\n",
      "        Oh42 |   1.56e-06   .0008879     0.00   0.999    -.0017386    .0017417\n",
      "        Il13 |   2.63e-06   .0011353     0.00   0.998    -.0022224    .0022277\n",
      "        Mo29 |  -4.54e-07   .0004885    -0.00   0.999    -.0009578    .0009569\n",
      "        In49 |   1.81e-06   .0010305     0.00   0.999     -.002018    .0020216\n",
      "        Mo06 |   2.74e-06   .0011603     0.00   0.998    -.0022714    .0022769\n",
      "       _cons |  -1.321655   .1972874    -6.70   0.000    -1.708332   -.9349792\n",
      "-------------+----------------------------------------------------------------\n",
      "eq2          |\n",
      "         sev |   .6355431    .169446     3.75   0.000      .303435    .9676511\n",
      "        sev2 |  -6.65e-07   .0005434    -0.00   0.999    -.0010657    .0010644\n",
      "    longname |   .0156384   .1173133     0.13   0.894    -.2142915    .2455683\n",
      "       lncas |    -.56674   .1653212    -3.43   0.001    -.8907636   -.2427164\n",
      "         td1 |   .0057885   .5178594     0.01   0.991    -1.009197    1.020774\n",
      "         td2 |   .0001012    .271248     0.00   1.000     -.531535    .5317375\n",
      "         td3 |  -2.33e-06   .0010031    -0.00   0.998    -.0019684    .0019638\n",
      "         td4 |  -.0027134   .3529641    -0.01   0.994    -.6945104    .6890835\n",
      "         td5 |  -.3087776   .3692058    -0.84   0.403    -1.032408    .4148525\n",
      "         td8 |  -.0056542   .1552916    -0.04   0.971    -.3100201    .2987116\n",
      "         td9 |   -.029187   .4701208    -0.06   0.950    -.9506069    .8922328\n",
      "        Ky22 |   8.19e-07   .0008409     0.00   0.999    -.0016473    .0016489\n",
      "        Oh16 |   4.23e-06   .0015218     0.00   0.998    -.0029785    .0029869\n",
      "        In54 |  -1.63e-06   .0010571    -0.00   0.999    -.0020734    .0020702\n",
      "        Oh42 |  -1.34e-06   .0007939    -0.00   0.999    -.0015574    .0015547\n",
      "        Il13 |   2.21e-06   .0012581     0.00   0.999    -.0024637    .0024681\n",
      "        Mo29 |  -5.40e-07    .000491    -0.00   0.999    -.0009628    .0009617\n",
      "        In49 |  -1.27e-06   .0007885    -0.00   0.999    -.0015468    .0015442\n",
      "        Mo06 |   2.47e-06   .0011011     0.00   0.998    -.0021556    .0021605\n",
      "       _cons |  -1.757635   .2431344    -7.23   0.000     -2.23417   -1.281101\n",
      "------------------------------------------------------------------------------\n",
      "Warning: convergence not achieved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "preserve\n",
    "drop if td6 | td10 | td7\n",
    "global xlist sev sev2 longname lncas td1 td2 td3 td4 td5 td8 td9 Ky22 Oh16 In54 Oh42 Il13 Mo29 In49 Mo06\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    st_view(w=.,.,\"w\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))*sqrt(2)/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1)/sqrt(2))^(1/2)   \n",
    "    printf(\"Lambda is\")\n",
    "    lambda\n",
    "    g = J(1,2,1)#I(cols(X))\n",
    "end\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gltril_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_eq_indepvars(M, 2, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 50000)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_technique(M, \"nm\")\n",
    "    moptimize_init_nmsimplexdeltas(M,J(1,cols(X),.1))\n",
    "    moptimize(M)\n",
    "\n",
    "    b = moptimize_result_coefs(M)\n",
    "end  \n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gltril_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_eq_indepvars(M, 2, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 500)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_eq_coefs(M,1,b[1::cols(b)/2])\n",
    "    moptimize_init_eq_coefs(M,2,b[cols(b)/2+1::cols(b)])\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this smaller dataset, we see that `sev`, `longname`, `lncas`, `td5`, `td8`, and `td9` matter. Accordingly, I reestimate the model and then create weights for estimates of the outcome equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   log likelihood =  -295.9093  \n",
      "Iteration 1:   log likelihood = -224.41593  \n",
      "Iteration 2:   log likelihood = -218.65211  \n",
      "Iteration 3:   log likelihood = -218.56947  \n",
      "Iteration 4:   log likelihood = -218.56934  \n",
      "Iteration 5:   log likelihood = -218.56934  \n",
      "\n",
      "Multinomial logistic regression                 Number of obs     =        335\n",
      "                                                LR chi2(12)       =     154.68\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log likelihood = -218.56934                     Pseudo R2         =     0.2614\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "     expoper |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "0            |  (base outcome)\n",
      "-------------+----------------------------------------------------------------\n",
      "1            |\n",
      "         sev |   1.416791   .1753769     8.08   0.000     1.073059    1.760524\n",
      "    longname |  -.2855911   .1639206    -1.74   0.081    -.6068696    .0356873\n",
      "       lncas |  -.0249432   .1639096    -0.15   0.879       -.3462    .2963137\n",
      "         td5 |   2.184377   .4431681     4.93   0.000     1.315783     3.05297\n",
      "         td8 |   1.827835   .6463365     2.83   0.005     .5610392    3.094632\n",
      "         td9 |  -.0097903   .4384622    -0.02   0.982    -.8691605    .8495799\n",
      "       _cons |  -1.884297   .2656542    -7.09   0.000    -2.404969   -1.363624\n",
      "-------------+----------------------------------------------------------------\n",
      "2            |\n",
      "         sev |   .7558627   .1821881     4.15   0.000     .3987805    1.112945\n",
      "    longname |   .0087141   .1896161     0.05   0.963    -.3629266    .3803547\n",
      "       lncas |  -.6887344   .1753622    -3.93   0.000    -1.032438   -.3450307\n",
      "         td5 |   -.641386   .7892299    -0.81   0.416    -2.188248    .9054762\n",
      "         td8 |  -.6696406   1.110481    -0.60   0.546    -2.846143    1.506862\n",
      "         td9 |   -1.81343   .7699993    -2.36   0.019    -3.322601    -.304259\n",
      "       _cons |  -1.603882   .2347973    -6.83   0.000    -2.064076   -1.143687\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "capture drop p0 p1 p2 w\n",
    "\n",
    "mlogit expoper sev longname lncas td5 td8 td9\n",
    "\n",
    "predict p0 p1 p2, p\n",
    "gen w = 1/p0*(expoper == 0) + 1/p1*(expoper == 1) + 1/p2*(expoper == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome equations\n",
    "\n",
    "I use the same methods as I did earlier - adding interactions for different treatments, and then grouping these interactions with coefficients. This ensures that the same variables will appear as controls in outcome equations. \n",
    "\n",
    "Here is the code that creates globals and interactions for all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "global xlist sev sev2 td1 td2 td3 td4 td5 td8 td9 Ky22 Oh16 In54 Oh42 Il13 Mo29 In49 Mo06\n",
    "global yvar outcome\n",
    "\n",
    "global xoutlist\n",
    "foreach variable in $xlist {\n",
    "    gen ia_`variable' = `variable'*(expoper == 1)\n",
    "    gen ie_`variable' = `variable'*(expoper == 2)\n",
    "    global xoutlist $xoutlist `variable' ia_`variable' ie_`variable'\n",
    "}\n",
    "\n",
    "gen amputation = (expoper == 1)\n",
    "global xoutlist $xoutlist amputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mata functions and implementation\n",
    "\n",
    "The next a new version of the mata function to lasso outcomes across the two treatments (and one non-treatment). The idea is to get predictor variables that are useful in predicting the incidence of surgery across all three outcome equations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "note: argument todo unused\n",
      "note: argument gr unused\n",
      "note: argument H unused\n",
      "\n",
      "convergence not achieved\n",
      "\n",
      "                                                Number of obs     =        335\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |  -.4457374   .1589992    -2.80   0.005    -.7573702   -.1341046\n",
      "      ia_sev |   .0079837   .2190762     0.04   0.971    -.4213978    .4373653\n",
      "      ie_sev |   .0610567   .1981181     0.31   0.758    -.3272477    .4493611\n",
      "        sev2 |  -.0000117   .0021237    -0.01   0.996    -.0041741    .0041508\n",
      "     ia_sev2 |  -8.88e-07   .0013854    -0.00   0.999    -.0027162    .0027145\n",
      "     ie_sev2 |   8.62e-07   .0013807     0.00   1.000    -.0027052    .0027069\n",
      "         td1 |   3.78e-06   .0014163     0.00   0.998    -.0027722    .0027798\n",
      "      ia_td1 |   1.15e-06   .0009567     0.00   0.999    -.0018739    .0018762\n",
      "      ie_td1 |   2.81e-06   .0011195     0.00   0.998    -.0021913     .002197\n",
      "         td2 |   1.88e-07   .0004154     0.00   1.000     -.000814    .0008143\n",
      "      ia_td2 |   1.60e-07   .0004166     0.00   1.000    -.0008164    .0008167\n",
      "      ie_td2 |  -2.04e-08   .0004487    -0.00   1.000    -.0008795    .0008795\n",
      "         td3 |   1.74e-08   .0005944     0.00   1.000     -.001165     .001165\n",
      "      ia_td3 |   8.51e-07   .0006198     0.00   0.999     -.001214    .0012157\n",
      "      ie_td3 |  -7.23e-07   .0005548    -0.00   0.999     -.001088    .0010866\n",
      "         td4 |   9.22e-07   .0006214     0.00   0.999    -.0012169    .0012188\n",
      "      ia_td4 |   6.18e-07   .0006246     0.00   0.999    -.0012236    .0012248\n",
      "      ie_td4 |   1.81e-07   .0005183     0.00   1.000    -.0010157    .0010161\n",
      "         td5 |   .1965161   .3449993     0.57   0.569    -.4796701    .8727023\n",
      "      ia_td5 |   .0100029   .1862119     0.05   0.957    -.3549657    .3749715\n",
      "      ie_td5 |   .1152141   .2566661     0.45   0.654    -.3878421    .6182703\n",
      "         td8 |  -7.22e-06   .0017037    -0.00   0.997    -.0033463    .0033319\n",
      "      ia_td8 |  -3.40e-06   .0013108    -0.00   0.998    -.0025725    .0025657\n",
      "      ie_td8 |   3.74e-07   .0011372     0.00   1.000    -.0022285    .0022293\n",
      "         td9 |   2.14e-07   .0004666     0.00   1.000    -.0009142    .0009147\n",
      "      ia_td9 |   2.19e-07   .0004714     0.00   1.000    -.0009237    .0009242\n",
      "      ie_td9 |   5.34e-07   .0005278     0.00   0.999     -.001034     .001035\n",
      "        Ky22 |  -1.46e-07   .0003876    -0.00   1.000    -.0007598    .0007595\n",
      "     ia_Ky22 |  -1.90e-07   .0004808    -0.00   1.000    -.0009426    .0009422\n",
      "     ie_Ky22 |   1.83e-07    .000426     0.00   1.000    -.0008348    .0008351\n",
      "        Oh16 |   1.41e-06   .0007568     0.00   0.999     -.001482    .0014848\n",
      "     ia_Oh16 |   5.58e-07   .0006292     0.00   0.999    -.0012327    .0012338\n",
      "     ie_Oh16 |   6.90e-07   .0006203     0.00   0.999     -.001215    .0012164\n",
      "        In54 |   2.37e-08   .0003821     0.00   1.000    -.0007489    .0007489\n",
      "     ia_In54 |  -4.94e-08   .0004011    -0.00   1.000    -.0007861     .000786\n",
      "     ie_In54 |   4.02e-07   .0004126     0.00   0.999    -.0008083    .0008091\n",
      "        Oh42 |  -1.12e-06    .000619    -0.00   0.999    -.0012144    .0012122\n",
      "     ia_Oh42 |  -1.02e-07    .000552    -0.00   1.000    -.0010821    .0010819\n",
      "     ie_Oh42 |   1.10e-07   .0005581     0.00   1.000    -.0010938     .001094\n",
      "        Il13 |   8.29e-07   .0005662     0.00   0.999    -.0011089    .0011106\n",
      "     ia_Il13 |   2.43e-07   .0005799     0.00   1.000    -.0011363    .0011368\n",
      "     ie_Il13 |   2.51e-07   .0005785     0.00   1.000    -.0011335     .001134\n",
      "        Mo29 |   1.07e-08   .0004085     0.00   1.000    -.0008006    .0008006\n",
      "     ia_Mo29 |   1.19e-08   .0003905     0.00   1.000    -.0007653    .0007653\n",
      "     ie_Mo29 |  -3.61e-08   .0004392    -0.00   1.000    -.0008609    .0008608\n",
      "        In49 |  -8.59e-07   .0005919    -0.00   0.999     -.001161    .0011593\n",
      "     ia_In49 |   1.63e-07   .0004999     0.00   1.000    -.0009796      .00098\n",
      "     ie_In49 |  -5.58e-07   .0005451    -0.00   0.999    -.0010689    .0010677\n",
      "        Mo06 |  -7.08e-07   .0005465    -0.00   0.999    -.0010718    .0010704\n",
      "     ia_Mo06 |  -3.57e-07   .0005087    -0.00   0.999    -.0009974    .0009967\n",
      "     ie_Mo06 |  -4.36e-07    .000506    -0.00   0.999    -.0009922    .0009914\n",
      "  amputation |  -.0873831   .3836864    -0.23   0.820    -.8393945    .6646284\n",
      "       _cons |   1.850872   .2126039     8.71   0.000     1.434176    2.267568\n",
      "------------------------------------------------------------------------------\n",
      "Warning: convergence not achieved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "mata:\n",
    "    void gll_aemata(M, todo, b, f, gr, H) {\n",
    "        \n",
    "        y  = moptimize_util_depvar(M, 1)\n",
    "        xb = moptimize_util_xb(M, b, 1)\n",
    "        \n",
    "        lam = moptimize_util_userinfo(M, 1)\n",
    "        g   = moptimize_util_userinfo(M, 2)\n",
    "        w   = moptimize_util_userinfo(M, 3)\n",
    "        w   = w/colsum(w)*rows(w)\n",
    "        \n",
    "        bt  = b[1::cols(b) - 2]\n",
    "        gb  = sqrt(rowsum(g)):*sqrt(rowsum((bt:^2):*g))\n",
    "        norm = colsum(gb)       \n",
    "       \n",
    "        lnf  = w:*((y :== 1) :*xb - ln(1 :+ exp(xb)))       \n",
    "        \n",
    "        f = sum(lnf) - norm*lam\n",
    "    }\n",
    "end   \n",
    "\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xoutlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    st_view(w=.,.,\"w\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))*sqrt(2)/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1)/sqrt(2))^(1/2) \n",
    "\n",
    "    g = I(cols(X)/3)#J(1,3,1)\n",
    "end\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_aemata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_conv_maxiter(M, 600)\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating treatment effects\n",
    "\n",
    "From the above, a parsimonious model of outcomes in the case includes: just `sev` and `td5`. In this case, 26 variables have been reduced to 2. \n",
    "\n",
    "Therefore, the lasso suggests the following parsimonious model of outcomes and selection into treatments (once again fit with `Stata`'s canned `teffects` package. When actually fitting the models, I will not do it this way because it is not clear what is happening under the hood. But, as a way of previewing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   EE criterion =  .00094578  \n",
      "Iteration 1:   EE criterion =  3.072e-06  \n",
      "Iteration 2:   EE criterion =  2.466e-06  \n",
      "Iteration 3:   EE criterion =  3.443e-08  \n",
      "Iteration 4:   EE criterion =  2.358e-10  \n",
      "\n",
      "Treatment-effects estimation                    Number of obs     =        335\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : logit by ML\n",
      "Treatment model: (multinomial) logit\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "ATE          |\n",
      "     expoper |\n",
      "   (1 vs 0)  |   .0014965   .0781815     0.02   0.985    -.1517365    .1547295\n",
      "   (2 vs 0)  |   .0894258   .0526902     1.70   0.090    -.0138451    .1926967\n",
      "-------------+----------------------------------------------------------------\n",
      "POmean       |\n",
      "     expoper |\n",
      "          0  |   .8098308   .0355713    22.77   0.000     .7401124    .8795492\n",
      "-------------+----------------------------------------------------------------\n",
      "OME0         |\n",
      "         sev |  -.6982977   .1759838    -3.97   0.000     -1.04322   -.3533757\n",
      "         td5 |    1.42728   1.080805     1.32   0.187    -.6910602    3.545619\n",
      "       _cons |   1.467613   .2011244     7.30   0.000     1.073416    1.861809\n",
      "-------------+----------------------------------------------------------------\n",
      "OME1         |\n",
      "         sev |  -.0878549   .4680883    -0.19   0.851    -1.005291    .8295813\n",
      "         td5 |   .5647202   1.033024     0.55   0.585    -1.459969    2.589409\n",
      "       _cons |    1.27458   .6786093     1.88   0.060    -.0554698     2.60463\n",
      "-------------+----------------------------------------------------------------\n",
      "OME2         |\n",
      "         sev |  -.3808604   .3654791    -1.04   0.297    -1.097186    .3354654\n",
      "         td5 |   6.753616   .8623279     7.83   0.000     5.063484    8.443747\n",
      "       _cons |   1.943097   .5353504     3.63   0.000     .8938296    2.992365\n",
      "-------------+----------------------------------------------------------------\n",
      "TME1         |\n",
      "         sev |   1.433483   .1664561     8.61   0.000     1.107235    1.759731\n",
      "    longname |  -.2748399   .1660505    -1.66   0.098    -.6002928     .050613\n",
      "       lncas |  -.0289727   .1757796    -0.16   0.869    -.3734945     .315549\n",
      "         td4 |    -.89833   .7214919    -1.25   0.213    -2.312428    .5157681\n",
      "         td5 |   2.079023   .4584595     4.53   0.000     1.180458    2.977587\n",
      "         td8 |    1.70903     .69336     2.46   0.014     .3500695    3.067991\n",
      "         td9 |   -.132821   .4342048    -0.31   0.760    -.9838468    .7182048\n",
      "       _cons |  -1.772965   .2372128    -7.47   0.000    -2.237893   -1.308036\n",
      "-------------+----------------------------------------------------------------\n",
      "TME2         |\n",
      "         sev |   .7623785   .1947713     3.91   0.000     .3806338    1.144123\n",
      "    longname |     .01418    .182424     0.08   0.938    -.3433644    .3717244\n",
      "       lncas |  -.6996833   .1708731    -4.09   0.000    -1.034588   -.3647783\n",
      "         td4 |  -.9585007   .6495952    -1.48   0.140    -2.231684    .3146826\n",
      "         td5 |  -.7633742   .8318226    -0.92   0.359    -2.393716     .866968\n",
      "         td8 |  -.7983501   1.110116    -0.72   0.472    -2.974137    1.377437\n",
      "         td9 |  -1.942049   .7389231    -2.63   0.009    -3.390311   -.4937861\n",
      "       _cons |  -1.480771   .2498634    -5.93   0.000    -1.970495    -.991048\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "teffects aipw (outcome sev td5, logit) (expoper sev longname lncas td4 td5 td8 td9, mlogit ), aequations\n",
    "\n",
    "restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "Some comments: \n",
    "\n",
    "1. Severity matters a lot in selection into treatment, and it matters alot for outcomes when not treated. But it looks as though amputation and resection/excision more or less mitigate the severity of the wound. \n",
    "\n",
    "2. The more complex procedure resection/excision seems to be strongly influenced by the battlefield setting. \n",
    "\n",
    "3. It could be argued that amputation seems to be a stop gap measure that works, but isn't as effective as more invasive treatments. The deal with amputation might also be that it was for wounds of the extremities, which have a high survival rate anyways. So, the change in the survival rate is estimated to be smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One last experiment\n",
    "\n",
    "Look at wounds that can be judged to be more critical, and fit our original model to them. So, what we will do is run a simple treatment and outcome Lasso on wounds to the head; hip; knee; leg; neck, trunk, or shoulder; and thigh. In most cases, these operations involved quite a bit more work and intricacy to get this to work, is the argument.\n",
    "\n",
    "So, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    critloc |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |        171       34.34       34.34\n",
      "          1 |        327       65.66      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |        498      100.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "gen critloc = td6 | td7 | td8 | td9 | td10 | td11\n",
    "tab critloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "already preserved\n",
      "r(621);\n",
      "\n",
      "(0 observations deleted)\n",
      "\n",
      "Lambda is\n",
      "  3.068787788\n",
      "\n",
      "Number variables\n",
      "  17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "global xlist sev sev2 lncas longname td6 td7 td8 td9 td10 Ky22 Oh16 In54 Oh42 Il13 Mo29 In49 Mo06\n",
    "global yvar operated\n",
    "preserve\n",
    "keep if critloc\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    w = J(rows(y),1,1)\n",
    "    \n",
    "    lambda = 2*max(abs(X))/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1))^(1/2)\n",
    "    printf(\"Lambda is\")\n",
    "    lambda\n",
    "    g = I(cols(X))\n",
    "    printf(\"Number variables\")\n",
    "    cols(X)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Treatment Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                Number of obs     =        327\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |   .8176354   .1545953     5.29   0.000     .5146341    1.120637\n",
      "        sev2 |   2.15e-06   .0015731     0.00   0.999     -.003081    .0030853\n",
      "       lncas |  -.4558087   .1352639    -3.37   0.001     -.720921   -.1906963\n",
      "    longname |   .0000125    .004524     0.00   0.998    -.0088544    .0088793\n",
      "         td6 |  -.5339225   .5361905    -1.00   0.319    -1.584837    .5169916\n",
      "         td7 |  -3.83e-08   .0003125    -0.00   1.000    -.0006125    .0006124\n",
      "         td8 |    .552261    .552753     1.00   0.318    -.5311149    1.635637\n",
      "         td9 |  -9.77e-08   .0003868    -0.00   1.000    -.0007582     .000758\n",
      "        td10 |  -8.17e-06   .0029865    -0.00   0.998    -.0058617    .0058453\n",
      "        Ky22 |   1.16e-07   .0007326     0.00   1.000    -.0014357     .001436\n",
      "        Oh16 |  -1.61e-07   .0005103    -0.00   1.000    -.0010003        .001\n",
      "        In54 |  -8.86e-07   .0007665    -0.00   0.999    -.0015031    .0015014\n",
      "        Oh42 |  -9.97e-08   .0004514    -0.00   1.000    -.0008849    .0008847\n",
      "        Il13 |  -2.06e-08   .0004617    -0.00   1.000    -.0009048    .0009048\n",
      "        Mo29 |  -6.86e-07     .00067    -0.00   0.999    -.0013138    .0013125\n",
      "        In49 |   .0348849    .576378     0.06   0.952    -1.094795    1.164565\n",
      "        Mo06 |   2.95e-06   .0014283     0.00   0.998    -.0027965    .0028024\n",
      "       _cons |  -1.350824   .1698844    -7.95   0.000    -1.683791   -1.017856\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl \n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_conv_maxiter(M, 5000)\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the variables not zeroed out be the lasso are `sev`, `lncas`, `td6`, `td8` and `In49`. One thing that is interesting is that the `longname` variable is zeroed. Maybe this is because soldiers wounded in these locations were in no position to argue!\n",
    "\n",
    "Now, let's estimate the outcome model, after dropping all the interactions we had before and remaking them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   log likelihood = -176.08924  \n",
      "Iteration 1:   log likelihood =  -140.0948  \n",
      "Iteration 2:   log likelihood = -137.54747  \n",
      "Iteration 3:   log likelihood = -137.50961  \n",
      "Iteration 4:   log likelihood =  -137.5095  \n",
      "Iteration 5:   log likelihood =  -137.5095  \n",
      "\n",
      "Logistic regression                             Number of obs     =        327\n",
      "                                                LR chi2(5)        =      77.16\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log likelihood =  -137.5095                     Pseudo R2         =     0.2191\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "    operated |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |   .8897476   .1607862     5.53   0.000     .5746124    1.204883\n",
      "       lncas |  -.5385554   .1420631    -3.79   0.000    -.8169939   -.2601169\n",
      "         td6 |  -1.686019   .7796402    -2.16   0.031    -3.214085    -.157952\n",
      "         td8 |   1.362451   .5488286     2.48   0.013     .2867666    2.438135\n",
      "        In49 |    .954729   .5432085     1.76   0.079    -.1099401    2.019398\n",
      "       _cons |  -1.461212    .179015    -8.16   0.000    -1.812075   -1.110349\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "logit $yvar sev lncas td6 td8 In49\n",
    "\n",
    "capture drop ps\n",
    "capture drop w\n",
    "predict ps, p\n",
    "\n",
    "gen w = operated*1/ps + (1-operated)*1/(1-ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stata -s gl\n",
    "capture drop io*\n",
    "\n",
    "global xoutlist\n",
    "foreach variable in $xlist {\n",
    "    gen io_`variable' = `variable'*operated\n",
    "    global xoutlist $xoutlist `variable' io_`variable'\n",
    "}\n",
    "\n",
    "global yvar outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda is\n",
      "  3.068787788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl \n",
    "mata:\n",
    "    st_view(X=.,.,\"$xoutlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    st_view(w=.,.,\"w\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1))^(1/2)\n",
    "    printf(\"Lambda is\")\n",
    "    lambda\n",
    "    g = I(cols(X)/2)#J(1,2,1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                Number of obs     =        327\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         sev |  -1.014939   .1980172    -5.13   0.000    -1.403045   -.6268322\n",
      "      io_sev |   .5234818   .2756887     1.90   0.058    -.0168581    1.063822\n",
      "        sev2 |  -3.65e-06   .0013575    -0.00   0.998    -.0026642    .0026569\n",
      "     io_sev2 |   9.93e-07   .0010051     0.00   0.999    -.0019689    .0019709\n",
      "       lncas |   .0150281    .114885     0.13   0.896    -.2101423    .2401985\n",
      "    io_lncas |   .1076849     .20834     0.52   0.605     -.300654    .5160237\n",
      "    longname |  -4.96e-07   .0006218    -0.00   0.999    -.0012192    .0012182\n",
      " io_longname |   1.11e-06   .0007265     0.00   0.999    -.0014228     .001425\n",
      "         td6 |  -2.73e-07   .0007733    -0.00   1.000     -.001516    .0015155\n",
      "      io_td6 |   9.20e-07   .0007003     0.00   0.999    -.0013717    .0013736\n",
      "         td7 |   1.25e-06   .0009442     0.00   0.999    -.0018494    .0018519\n",
      "      io_td7 |   1.95e-06   .0010079     0.00   0.998    -.0019735    .0019774\n",
      "         td8 |  -.4623694   .4380569    -1.06   0.291    -1.320945    .3962063\n",
      "      io_td8 |  -.2627778   .3606578    -0.73   0.466    -.9696542    .4440986\n",
      "         td9 |   .0213963    .300216     0.07   0.943    -.5670162    .6098088\n",
      "      io_td9 |   .0185351   .2665068     0.07   0.945    -.5038087    .5408788\n",
      "        td10 |  -.4087316    .351986    -1.16   0.246    -1.098612    .2811483\n",
      "     io_td10 |    .698083   .5050422     1.38   0.167    -.2917816    1.687947\n",
      "        Ky22 |   6.06e-07   .0007294     0.00   0.999     -.001429    .0014302\n",
      "     io_Ky22 |   6.45e-07   .0007142     0.00   0.999    -.0013992    .0014005\n",
      "        Oh16 |   .0849944   .2641054     0.32   0.748    -.4326426    .6026314\n",
      "     io_Oh16 |   .1540352   .4435877     0.35   0.728    -.7153807    1.023451\n",
      "        In54 |  -2.12e-06   .0010078    -0.00   0.998    -.0019773    .0019731\n",
      "     io_In54 |  -6.09e-07   .0007753    -0.00   0.999    -.0015201    .0015189\n",
      "        Oh42 |  -9.18e-07   .0008167    -0.00   0.999    -.0016015    .0015997\n",
      "     io_Oh42 |  -5.25e-08   .0006275    -0.00   1.000    -.0012299    .0012298\n",
      "        Il13 |   3.92e-06     .00197     0.00   0.998    -.0038572     .003865\n",
      "     io_Il13 |   2.88e-06   .0016277     0.00   0.999    -.0031873     .003193\n",
      "        Mo29 |  -5.89e-07   .0005445    -0.00   0.999    -.0010677    .0010665\n",
      "     io_Mo29 |   3.36e-07   .0007194     0.00   1.000    -.0014098    .0014104\n",
      "        In49 |  -2.23e-06   .0010485    -0.00   0.998    -.0020572    .0020528\n",
      "     io_In49 |   1.43e-06    .000918     0.00   0.999    -.0017979    .0018007\n",
      "        Mo06 |  -2.00e-06   .0010559    -0.00   0.998    -.0020714    .0020674\n",
      "     io_Mo06 |  -1.92e-06    .001026    -0.00   0.999    -.0020129     .002009\n",
      "       _cons |   1.315155   .2176098     6.04   0.000     .8886478    1.741663\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 50000)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize_init_technique(M, \"nm\")\n",
    "    moptimize_init_nmsimplexdeltas(M,J(1,cols(X),.05))\n",
    "    moptimize(M)\n",
    "    b = moptimize_result_coefs(M)\n",
    "end  \n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_userinfo(M, 3, w)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 1000)\n",
    "    moptimize_init_trace_value(M, \"off\") \n",
    "    moptimize_init_eq_coefs(M, 1, b)    \n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0:   EE criterion =  .00093233  \n",
      "Iteration 1:   EE criterion =  3.724e-06  \n",
      "Iteration 2:   EE criterion =  2.682e-06  \n",
      "Iteration 3:   EE criterion =  7.865e-08  \n",
      "Iteration 4:   EE criterion =  1.318e-10  \n",
      "\n",
      "Treatment-effects estimation                    Number of obs     =        327\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : logit by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "ATE          |\n",
      "    operated |\n",
      "   (1 vs 0)  |   .1744163   .0466182     3.74   0.000     .0830464    .2657863\n",
      "-------------+----------------------------------------------------------------\n",
      "POmean       |\n",
      "    operated |\n",
      "          0  |   .6800866   .0315865    21.53   0.000     .6181781    .7419951\n",
      "-------------+----------------------------------------------------------------\n",
      "OME0         |\n",
      "         sev |   -1.32716   .2071462    -6.41   0.000    -1.733159   -.9211608\n",
      "       lncas |  -.1639266   .1903689    -0.86   0.389    -.5370427    .2091896\n",
      "         td8 |  -.9989601   .8525028    -1.17   0.241    -2.669835    .6719148\n",
      "         td9 |   .2778294   .5617737     0.49   0.621    -.8232268    1.378886\n",
      "        td10 |  -.6496653   .3506319    -1.85   0.064    -1.336891    .0375605\n",
      "        Oh16 |  -.2029771   .5426802    -0.37   0.708    -1.266611    .8606565\n",
      "       _cons |   1.061833   .2527593     4.20   0.000     .5664341    1.557232\n",
      "-------------+----------------------------------------------------------------\n",
      "OME1         |\n",
      "         sev |   -.418438   .3486759    -1.20   0.230     -1.10183    .2649542\n",
      "       lncas |    .131613   .2308014     0.57   0.569    -.3207495    .5839755\n",
      "         td8 |  -.4652166   .9090288    -0.51   0.609     -2.24688    1.316447\n",
      "         td9 |    1.31107   .9218809     1.42   0.155    -.4957834    3.117923\n",
      "        td10 |   1.091463   .8105335     1.35   0.178     -.497153     2.68008\n",
      "        Oh16 |   6.552584   .8232626     7.96   0.000     4.939019    8.166149\n",
      "       _cons |     1.1561   .4144263     2.79   0.005     .3438397    1.968361\n",
      "-------------+----------------------------------------------------------------\n",
      "TME1         |\n",
      "         sev |   .8897476   .1707427     5.21   0.000     .5550982    1.224397\n",
      "       lncas |  -.5385554   .1484926    -3.63   0.000    -.8295956   -.2475152\n",
      "         td6 |  -1.686019    .714529    -2.36   0.018     -3.08647   -.2855676\n",
      "         td8 |   1.362451   .5989671     2.27   0.023     .1884969    2.536405\n",
      "        In49 |    .954729   .5340561     1.79   0.074    -.0920017     2.00146\n",
      "       _cons |  -1.461212   .1721338    -8.49   0.000    -1.798588   -1.123836\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "teffects aipw (outcome sev lncas td8 td9 td10 Oh16, logit) (operated sev lncas td6 td8 In49, logit), aequations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On to the Next Workbook\n",
    "\n",
    "The primary purpose of this workbook was to pare down the models with the lasso. Please see [this workbook](Estimation Tables and Figures for Presentation.ipynb) for the next step, which involves formally estimating models and treatment effects, and computing standard errors.  \n",
    "\n",
    "For the time being, I am going to leave the above analysis out of the paper, but I will mention it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
