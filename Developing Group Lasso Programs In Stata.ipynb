{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Group Lasso Program\n",
    "\n",
    "In this digression, the idea is to illustrate how one might program a functional (and perhaps crude) group Lasso program in `Stata`\\`Mata`. Most of what follows is done using the material described in [Farrell (2015)](https://arxiv.org/abs/1309.4686). In addition to containing the theoretical justification for using a group lasso in conjunction with a doubly-robust estimator of treatment effects, this paper also contains many practical details.\n",
    "\n",
    "### Coefficients and the Lasso\n",
    "\n",
    "The grouped lasso is useful in circumstances where one is effectively fitting a series of regressions/equations, but wishes to maintain consistency across variables used in the regressions. So, a leading application of a grouped lasso is one in which the lasso is set up to let coefficients across all regressions be zero or positive. \n",
    "\n",
    "Suppose that coefficients fall into different groups, and group $g$ has a total of $N_g$ coefficients, with coefficient group $g$ as $\\beta_g=\\beta_{1g},\\beta_{2g},...,\\beta_{N_gg}$. While the groups may be grouped regression coefficients, they might also be dummies that go together in an obvious manner; education or income levels, age groups, etc.\n",
    "\n",
    "The usual lasso tacks on a penalty function of the form $(|\\beta_1| + |\\beta_2| + ... )$ to the objective function. The group lasso uses a mixed $\\ell_1\\ell_2$ norm, as described in [Yuan and Lin (2006)]( http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00532.x/abstract), so if we have $G$ groups with $N_g, g=1,2,...,G$ coefficients in them, we have the penalty function:\n",
    "\n",
    "$$\n",
    "P(\\beta)=w_1\\sqrt{\\left(|\\beta_{11}|+|\\beta_{21}|+...+|\\beta_{N_11}|\\right)^2} +w_2\\sqrt{\\left(|\\beta_{12}|+|\\beta_{22}|+...+|\\beta_{N_22}|\\right)^2}+...+w_G\\sqrt{\\left(|\\beta_{1G}|+|\\beta_{2G}|+...+|\\beta_{N_GG}|\\right)^2}\n",
    "$$\n",
    "\n",
    "The weights $w_1,w_2,...,w_{NG}$ are usually taken to be $\\sqrt{N_g}$ to also take into account group size.\n",
    "\n",
    "For any trivial group - a group with a sole parameter - the group lasso collapses to the the usual lasso. For groups with multiple parameters, however, the above penalty scheme forces all the parameters in the group to be different than zero or zero.\n",
    "\n",
    "\n",
    "## Objective function \n",
    "\n",
    "The modified objective function to be minimized is something like:\n",
    "\n",
    "$$\n",
    "L = f(y,x,\\beta)- \\lambda P(\\beta)\n",
    "$$\n",
    "\n",
    "Where $f(y,x,\\beta)$ could be just about anything (the negative of a likelihood perhaps, or some other thing of even a simple quadratic like $-(y-X\\beta)'(y-X\\beta)$). This is maximized given the lasso penalty. So, one must decide on $\\lambda$, which depends upon circumstances. We will get in to this a bit below, following  [Farrell (2015)](https://arxiv.org/abs/1309.4686). \n",
    "\n",
    "## Some Data\n",
    "\n",
    "We begin the mock up of the group lasso using `ipystata`. The ideas here will be extended and applied on the fly as I fit actual models. \n",
    "\n",
    "The last line of code renders a global macro for ease of passing around extended variable lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated 1 unattached Stata session(s).\n"
     ]
    }
   ],
   "source": [
    "import ipystata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start with the standard **`auto.dta`** data that comes with Stata, and form a model of whether or not a car is foreign using things like its price, repair record, size, gas mileage, etc. I'll add in a few categorical variables as this is a situation in which the group lasso is often applied. \n",
    "\n",
    "Following [Farrell (2015)](https://arxiv.org/abs/1309.4686) **Remark 4, page 10**, it helps to standardize the variables. One does not wish that units of measure impact a decision to include a coefficient. As I standardize, I also get the maximum (absolute) value of an observation, and the number of observations, because these both figure into the calcululation of the penalty weight $\\lambda$ [Farrell (2015)](https://arxiv.org/abs/1309.4686) describes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1978 Automobile Data)\n",
      "\n",
      "(0 observations deleted)\n",
      "\n",
      "     Repair |\n",
      "Record 1978 |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          1 |          2        2.90        2.90\n",
      "          2 |          8       11.59       14.49\n",
      "          3 |         30       43.48       57.97\n",
      "          4 |         18       26.09       84.06\n",
      "          5 |         11       15.94      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |         69      100.00\n",
      "\n",
      "    dispcat |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |         14       18.92       18.92\n",
      "        100 |         41       55.41       74.32\n",
      "        250 |         19       25.68      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |         74      100.00\n",
      "\n",
      "  weightcat |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |         19       25.68       25.68\n",
      "       2250 |         18       24.32       50.00\n",
      "       3200 |         28       37.84       87.84\n",
      "       4000 |          9       12.16      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |         74      100.00\n",
      "\n",
      ". foreach v of global contvars {\n",
      "  2.     quietly sum `v'\n",
      "  3.     replace `v' = (`v' - r(mean))/r(sd)\n",
      "  4.     sum `v'\n",
      "  5.     scalar test = max(abs(r(min)),abs(r(max)))\n",
      "  6.     if test > Max {\n",
      "  7.         scalar Max = test\n",
      "  8.     }\n",
      "  9. }\n",
      "variable price was int now float\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "       price |         74   -4.83e-10           1  -.9744909   3.302511\n",
      "variable rep78 was int now float\n",
      "(69 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "       rep78 |         69    8.64e-10           1  -2.430264   1.610416\n",
      "variable mpg was int now float\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "         mpg |         74   -7.00e-09           1  -1.606999    3.40553\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "    headroom |         74   -1.47e-08           1  -1.765074   2.372068\n",
      "variable weight was int now float\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      weight |         74   -1.81e-09           1  -1.620522   2.342454\n",
      "variable length was int now float\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      length |         74    1.06e-09           1  -2.062864   2.024022\n",
      "variable turn was int now float\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "        turn |         74   -2.82e-09           1  -1.965891   2.580232\n",
      "(74 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "  gear_ratio |         74    5.34e-09           1  -1.807776   1.917949\n",
      "\n",
      "price rep78 mpg headroom weight length turn gear_ratio wedum1 wedum2 wedum3 rdum1 rdum2 rdum3 di\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "sysuse auto, clear\n",
    "\n",
    "drop if rep == 0\n",
    "\n",
    "tab rep78, gen(rdum)                       // Generate some categorical variables\n",
    "\n",
    "egen dispcat = cut(displacement), at(0, 100, 250, 500)   // Another categorical variable\n",
    "tab dispcat, gen(dispdum)\n",
    "\n",
    "egen weightcat = cut(weight), at(0, 2250, 3200, 4000, 10000)  // Yet another categorical variable\n",
    "tab weightcat, gen(wedum)\n",
    "\n",
    "global contvars price rep78 mpg headroom weight length turn gear_ratio\n",
    "\n",
    "scalar Max = 0\n",
    "foreach v of global contvars {\n",
    "    quietly sum `v'\n",
    "    replace `v' = (`v' - r(mean))/r(sd)\n",
    "    sum `v'\n",
    "    scalar test = max(abs(r(min)),abs(r(max)))\n",
    "    if test > Max {\n",
    "        scalar Max = test\n",
    "    }\n",
    "}\n",
    "\n",
    "scalar N = r(N)\n",
    "\n",
    "global yvar foreign\n",
    "global xlist $contvars wedum1 wedum2 wedum3 rdum1 rdum2 rdum3 dispdum1 dispdum2\n",
    "disp \"$xlist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a series of variables which we can use in our mock-up analysis, some of which fall into groups: (`weightcat`, `dispcat`, e.g.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of Lambda \n",
    "\n",
    "Since I am working with discrete outcomes, I set the $\\lambda$ parameter according to what  [Farrell (2015)](https://arxiv.org/abs/1309.4686) suggests when the model is discrete/categorical. In this case, he suggests setting $\\lambda$ as:\n",
    "\n",
    "$$\n",
    "\\lambda_D = \\frac{2\\mathcal{X}\\sqrt{\\mathcal{T}}}{\\sqrt{n}}\\left(1+\\frac{\\log(p \\vee n)^{3/2+\\delta_D}}{\\sqrt{\\mathcal{T}}}\\right)^{1/2}\n",
    "$$\n",
    "\n",
    "In the above, $\\mathcal{X}$ is the maximum absolute value of any of the variables in the sample. Since I have standardized all the variables, this shouldn't be much bigger than $2$; I set it at 3.4 to be safe (this is the maximum value in the above standardized variable set). $\\mathcal{T}$ is the number of treatments, which is just unity (more would mean we have something like a multinomial logistic model and multiple treatments). Since $n$ is larger than $p$, and $n=74$, we have $p \\vee n = 74$. And to be safe, I set $\\delta_D=1$. \n",
    "\n",
    "In the implementation, I'm going to use a \"grouping\" matrix to collect coefficients belonging to the same group. We will also print out the calculated components of $\\lambda_D$, just to see that they are sensible. Here goes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Mata-based treatment of the problem\n",
    "\n",
    "`Mata` admits more control over the whole process, and also is a bit more compact in the coding. So, here is a Mata implementation. Really, all that one needs to do is look at the resulting coefficient estimates and see which ones are effectively zero and which ones are not. Once this step is done, I can then apply the usual Stata tools in estimating the model. \n",
    "\n",
    "### Additional comments:\n",
    "\n",
    "1. The objective function is a little spiky, so it is helpful to use the `hybrid` option for the Hessian. If there are a large number of coefficients, it helps to use Nelder-Mead optimization followed by the usual methods. \n",
    "2. Setting `maxiter` is also helpful. The optimization routine sometimes finds the minimum, but doesn't recognize it because $H$ is singular at this point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------- mata (type end to exit) ----------------------\n",
      "note: argument todo unused\n",
      "note: argument gr unused\n",
      "note: argument H unused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1))^(1/2)\n",
    "\n",
    "    g = 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0 \\ \n",
    "        0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0 \\\n",
    "        0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0 \\\n",
    "        0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0 \\\n",
    "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1\n",
    "end\n",
    "\n",
    "mata:\n",
    "    void gll_mata(M, todo, b, f, gr, H) {\n",
    "        \n",
    "        y  = moptimize_util_depvar(M, 1)\n",
    "        xb = moptimize_util_xb(M, b, 1)\n",
    "        \n",
    "        lam = moptimize_util_userinfo(M, 1)\n",
    "        g   = moptimize_util_userinfo(M, 2)\n",
    " \n",
    "        bt  = b[1::cols(b) - 1]\n",
    "        gb  = sqrt(rowsum(g)):*sqrt(rowsum((bt:^2):*g))\n",
    "        norm = colsum(gb)       \n",
    "       \n",
    "        lnf  = (y :== 1) :*xb - ln(1 :+ exp(xb))       \n",
    "        \n",
    "        f = sum(lnf) - norm*lam\n",
    "    }\n",
    "end    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------- mata (type end to exit) ----------------------\n",
      "                                                Number of obs     =         74\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "       price |   2.06e-07   .0002986     0.00   0.999    -.0005851    .0005855\n",
      "       rep78 |    .599299   .4103106     1.46   0.144    -.2048951    1.403493\n",
      "         mpg |   1.28e-08   .0001841     0.00   1.000    -.0003607    .0003608\n",
      "    headroom |  -8.96e-08   .0001904    -0.00   1.000    -.0003733    .0003731\n",
      "      weight |  -1.16e-07   .0004639    -0.00   1.000    -.0009093     .000909\n",
      "      length |  -1.03e-06   .0006823    -0.00   0.999    -.0013383    .0013362\n",
      "        turn |  -.4514483   .5245564    -0.86   0.389     -1.47956    .5766634\n",
      "  gear_ratio |   1.103175   .4893916     2.25   0.024     .1439853    2.062365\n",
      "      wedum1 |   3.13e-08   .0001514     0.00   1.000    -.0002967    .0002967\n",
      "      wedum2 |   8.29e-08   .0001601     0.00   1.000    -.0003136    .0003138\n",
      "      wedum3 |  -8.09e-08   .0001626    -0.00   1.000    -.0003187    .0003186\n",
      "       rdum1 |  -4.17e-09   .0001456    -0.00   1.000    -.0002853    .0002853\n",
      "       rdum2 |  -6.99e-09   .0001352    -0.00   1.000    -.0002649    .0002649\n",
      "       rdum3 |  -3.44e-08   .0001097    -0.00   1.000     -.000215     .000215\n",
      "    dispdum1 |   1.05e-08   .0000842     0.00   1.000     -.000165     .000165\n",
      "    dispdum2 |  -3.88e-09   .0001476    -0.00   1.000    -.0002893    .0002893\n",
      "       _cons |  -1.278951   .3912189    -3.27   0.001    -2.045726   -.5121756\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gll_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_conv_maxiter(M, 500)\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see from the above output that `rep78`, `turn`, and `gear_ratio` are picked out by the Lasso as being variables with enough explanatory power for inclusion in the model, with the rest of the coefficients/grouped terms effectively having coefficients of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Program #2: Lasso with multiple treatments\n",
    "\n",
    "It also helps to have a few methods available for a multi-leveled situation in which there are multiple treatments/outcomes. The idea here is to group coefficients across multiple linear forms that may appear in a model. Here is a group lasso program with multiple treatments, trinomial logit outcomes, and other stuff. \n",
    "\n",
    "Note that the key challenge is unpacking `Mata`'s coefficient vector $b$ into its two components, which have equal numbers of parts. I simply split it down the middle and then consider the coefficient vector in its entirety without the very last entry, as this is the constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------- mata (type end to exit) ----------------------\n",
      "note: argument todo unused\n",
      "note: argument gr unused\n",
      "note: argument H unused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "mata:\n",
    "    void gltril_mata(M, todo, b, f, gr, H) {\n",
    "        \n",
    "        y   = moptimize_util_depvar(M, 1)\n",
    "        xb1 = moptimize_util_xb(M, b, 1)\n",
    "        xb2 = moptimize_util_xb(M, b, 2)\n",
    "\n",
    "        lam = moptimize_util_userinfo(M, 1)\n",
    "        g   = moptimize_util_userinfo(M, 2)\n",
    " \n",
    "        b1  = b[1::cols(b)/2]\n",
    "        b2  = b[cols(b)/2 + 1::cols(b)]\n",
    "\n",
    "        b1 = b1[1::cols(b1)-1]\n",
    "        b2 = b2[1::cols(b2)-1]\n",
    "\n",
    "        bt = b1, b2\n",
    "\n",
    "        gb  = sqrt(rowsum(g)):*sqrt(rowsum((bt:^2):*g))\n",
    "        norm = colsum(gb)       \n",
    "    \n",
    "        lnf  = (y :== 1) :*xb1 + (y :==2 ) :*xb2 - ln(1 :+ exp(xb1) :+ exp(xb2))       \n",
    "        \n",
    "        f = sum(lnf) - norm*lam\n",
    "    }\n",
    "end   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A test run of the new program\n",
    "\n",
    "Here, we test out the new program using a different data set. This is the `mlogit` data set that one can get online from the below-referenced website. I also followed some of the documentation available at [this site](https://stats.idre.ucla.edu/stata/output/multinomial-logistic-regression/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(highschool and beyond (200 cases))\n",
      "\n",
      "Contains data from https://stats.idre.ucla.edu/stat/stata/output/mlogit.dta\n",
      "  obs:           200                          highschool and beyond (200 cases)\n",
      " vars:             5                          3 Apr 2007 14:04\n",
      " size:         4,000                          \n",
      "------------------------------------------------------------------------------------------------\n",
      "              storage   display    value\n",
      "variable name   type    format     label      variable label\n",
      "------------------------------------------------------------------------------------------------\n",
      "id              float   %9.0g                 \n",
      "female          float   %9.0g      fl         gender\n",
      "ice_cream       float   %10.0g     ic         favorite flavor of ice cream\n",
      "video           float   %9.0g                 score on video game\n",
      "puzzle          float   %9.0g                 score on puzzle game\n",
      "------------------------------------------------------------------------------------------------\n",
      "Sorted by: \n",
      "\n",
      "(200 differences between ice_cream and ice)\n",
      "\n",
      "  RECODE of |\n",
      "  ice_cream |\n",
      "  (favorite |\n",
      "  flavor of |\n",
      " ice cream) |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |         47       23.50       23.50\n",
      "          1 |         95       47.50       71.00\n",
      "          2 |         58       29.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |        200      100.00\n",
      "\n",
      "Iteration 0:   log likelihood = -210.58254  \n",
      "Iteration 1:   log likelihood = -194.69274  \n",
      "Iteration 2:   log likelihood = -194.03531  \n",
      "Iteration 3:   log likelihood = -194.03485  \n",
      "Iteration 4:   log likelihood = -194.03485  \n",
      "\n",
      "Multinomial logistic regression                 Number of obs     =        200\n",
      "                                                LR chi2(6)        =      33.10\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log likelihood = -194.03485                     Pseudo R2         =     0.0786\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "         ice |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "0            |\n",
      "       video |  -.0235647   .0209747    -1.12   0.261    -.0646744     .017545\n",
      "      puzzle |  -.0389243   .0195165    -1.99   0.046    -.0771759   -.0006726\n",
      "      female |   .8166202   .3909813     2.09   0.037      .050311    1.582929\n",
      "       _cons |   1.912256   1.127256     1.70   0.090    -.2971258    4.121638\n",
      "-------------+----------------------------------------------------------------\n",
      "1            |  (base outcome)\n",
      "-------------+----------------------------------------------------------------\n",
      "2            |\n",
      "       video |    .022922   .0208718     1.10   0.272    -.0179861    .0638301\n",
      "      puzzle |   .0430036   .0198894     2.16   0.031     .0040211     .081986\n",
      "      female |   -.032862   .3500153    -0.09   0.925    -.7188793    .6531553\n",
      "       _cons |  -4.057323   1.222939    -3.32   0.001     -6.45424   -1.660407\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "use https://stats.idre.ucla.edu/stat/stata/output/mlogit, clear\n",
    "\n",
    "describe    \n",
    "    \n",
    "recode ice_cream (1 = 0) (2 = 1) (3 = 2), generate(ice)    \n",
    "tab ice\n",
    "\n",
    "mlogit ice video puzzle female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the multiple lasso program, compute a series of interactions that we wish to pare down in fitting the actual model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "gen video2    = video*video\n",
    "gen puzzle2   = puzzle*puzzle\n",
    "\n",
    "gen vidpuz    = video*puzzle\n",
    "gen vidfem    = video*female\n",
    "gen vidpuzfem = video*puzzle*female\n",
    "\n",
    "global xlist video puzzle female video2 puzzle2 vidpuz vidfem vidpuzfem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing the variables\n",
    "\n",
    "As noted above, it is useful to standardize all the variables so the actual units don't wind up entering into the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". foreach v of global xlist {\n",
      "  2.     quietly sum `v'\n",
      "  3.     replace `v' = (`v' - r(mean))/r(sd)\n",
      "  4.     sum `v'\n",
      "  5.     scalar test = max(abs(r(min)),abs(r(max)))\n",
      "  6.     if test > Max {\n",
      "  7.         scalar Max = test\n",
      "  8.     }\n",
      "  9. }\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "       video |        200   -2.94e-09           1  -2.610876   2.237172\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      puzzle |        200   -7.38e-09           1  -2.459529   1.732056\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      female |        200   -2.24e-08           1  -1.091702   .9114209\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      video2 |        200    4.28e-09           1  -2.078781    2.65029\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "     puzzle2 |        200    5.29e-09           1  -2.005126   2.000601\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      vidpuz |        200   -1.36e-09           1  -2.192555   2.323538\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      vidfem |        200    8.83e-09           1  -1.055775   1.580796\n",
      "(200 real changes made)\n",
      "\n",
      "    Variable |        Obs        Mean    Std. Dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "   vidpuzfem |        200    4.27e-09           1  -.9909595   2.276127\n",
      "\n",
      "200\n",
      "\n",
      "2.6502898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl\n",
    "\n",
    "scalar Max = 0\n",
    "foreach v of global xlist {\n",
    "    quietly sum `v'\n",
    "    replace `v' = (`v' - r(mean))/r(sd)\n",
    "    sum `v'\n",
    "    scalar test = max(abs(r(min)),abs(r(max)))\n",
    "    if test > Max {\n",
    "        scalar Max = test\n",
    "    }\n",
    "}\n",
    "\n",
    "scalar N = r(N)\n",
    "\n",
    "disp N \n",
    "disp Max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculating grouping matrix and $\\lambda$\n",
    "\n",
    "We now have to recompute $\\lambda$, as our data is a bit different. The key is that now our number of treated groups is $\\mathcal{T}=2$, whereas it was just unity in the simple multinomial logit model. For ease of exposition, let's reproduce the formula here:\n",
    "\n",
    "$$\n",
    "\\lambda_D = \\frac{2\\mathcal{X}\\sqrt{\\mathcal{T}}}{\\sqrt{n}}\\left(1+\\frac{\\log(p \\vee n)^{3/2+\\delta_D}}{\\sqrt{\\mathcal{T}}}\\right)^{1/2}\n",
    "$$\n",
    "\n",
    "In this case, we haven't really grouped variables, so we just need an identity matrix as our \"grouping\" matrix, which conforms with the number of variables. Note how the grouping matrix has to be expanded so it has the form:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccccc}\n",
    "1 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & \\dots\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Thus it picks out the first coefficient in the first equation and the first in the second, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "convergence not achieved\n",
      "\n",
      "                                                Number of obs     =        200\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "eq1          |\n",
      "       video |   5.49e-06   .0016521     0.00   0.997    -.0032326    .0032435\n",
      "      puzzle |   2.40e-06   .0011711     0.00   0.998    -.0022928    .0022976\n",
      "      female |  -.1617904   .1825151    -0.89   0.375    -.5195135    .1959327\n",
      "      video2 |   8.96e-07   .0008129     0.00   0.999    -.0015924    .0015942\n",
      "     puzzle2 |   .0462398   .2139496     0.22   0.829    -.3730938    .4655733\n",
      "      vidpuz |   .2994924   .2591366     1.16   0.248    -.2084059    .8073908\n",
      "      vidfem |  -.0000125   .0023082    -0.01   0.996    -.0045365    .0045116\n",
      "   vidpuzfem |  -3.98e-06   .0013142    -0.00   0.998    -.0025797    .0025717\n",
      "       _cons |   .7857405   .1886221     4.17   0.000      .416048    1.155433\n",
      "-------------+----------------------------------------------------------------\n",
      "eq2          |\n",
      "       video |   5.49e-06   .0016757     0.00   0.997    -.0032788    .0032897\n",
      "      puzzle |   3.13e-06   .0014328     0.00   0.998    -.0028052    .0028115\n",
      "      female |  -.1384221   .1964168    -0.70   0.481     -.523392    .2465478\n",
      "      video2 |   2.00e-06    .000998     0.00   0.998    -.0019541    .0019581\n",
      "     puzzle2 |   .1681732   .4152955     0.40   0.686     -.645791    .9821374\n",
      "      vidpuz |   .6888849   .4272215     1.61   0.107    -.1484539    1.526224\n",
      "      vidfem |  -2.04e-06   .0016336    -0.00   0.999    -.0032039    .0031998\n",
      "   vidpuzfem |  -2.51e-08   .0009589    -0.00   1.000    -.0018794    .0018793\n",
      "       _cons |    .207807    .212429     0.98   0.328    -.2085462    .6241601\n",
      "------------------------------------------------------------------------------\n",
      "Warning: convergence not achieved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata -s gl -os\n",
    "global xlist video puzzle female video2 puzzle2 vidpuz vidfem vidpuzfem\n",
    "global yvar ice\n",
    "mata:\n",
    "    st_view(X=.,.,\"$xlist\")\n",
    "    st_view(y=.,.,\"$yvar\")\n",
    "    \n",
    "    lambda = 2*max(abs(X))*sqrt(2)/sqrt(rows(X))*(1+ln(rows(X))^(3/2+1)/sqrt(2))^(1/2)   \n",
    "    \n",
    "    g = J(1,2,1)#I(cols(X))\n",
    "end\n",
    "\n",
    "mata:\n",
    "    M = moptimize_init()\n",
    "    moptimize_init_evaluator(M, &gltril_mata())\n",
    "    moptimize_init_evaluatortype(M, \"d0\")\n",
    "    moptimize_init_eq_indepvars(M, 1, X)\n",
    "    moptimize_init_eq_indepvars(M, 2, X)\n",
    "    moptimize_init_depvar(M, 1, y)\n",
    "    moptimize_init_userinfo(M, 1, lambda)\n",
    "    moptimize_init_userinfo(M, 2, g)\n",
    "    moptimize_init_conv_maxiter(M, 500)\n",
    "    moptimize_init_singularHmethod(M, \"hybrid\")\n",
    "    moptimize_init_trace_value(M, \"off\")\n",
    "    moptimize(M)\n",
    "    moptimize_result_display(M)\n",
    "end   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "From the results, one can see how the group lasso has worked on the estimated model. The results suggest that for the grouped logit, `video`, `puzzle`, `video2`, `vidfem`, and `vidpuzfem` can be dropped to get a more parsimonious model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Going Forward\n",
    "\n",
    "In the interests of transparency, I shall include `Mata` code for the lasso program in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
